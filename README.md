# Leepookie Meme Reactor (AI Gesture â†’ Meme Player)

A realâ€‘time gestureâ€‘controlled meme generator using **MediaPipe Holistic**, a **machineâ€‘learning gesture classifier**, and **OpenCV**.  

When you perform a gesture in front of your webcam, the app predicts the gesture and instantly plays the matching meme GIF.

Perfect for VS Code demos, TikTok/Reels videos, and coding fun with friends.

---
## âœ¨ Features
- Realâ€‘time webcam tracking (face + hands)
- MLâ€‘trained gesture classifier (Random Forest)
- Smooth, stable predictions using majorityâ€‘vote filtering
- Animated GIF playback
- Easy dataset capture and model retraining
- Fully customizable gesture â†’ meme mapping

---
## ğŸ“¦ Project Structure
```
MemeProject/
â”‚
â”œâ”€â”€ data_capture.py       # Capture gesture samples
â”œâ”€â”€ train_model.py        # Train RandomForest model
â”œâ”€â”€ build_dataset.py      # (Optional) Build dataset from .npy files
â”œâ”€â”€ main.py               # Final real-time meme reactor
â”‚
â”œâ”€â”€ gesture_model.pkl     # Model generated after training
â”œâ”€â”€ dataset.npz           # Combined dataset
â”‚
â”œâ”€â”€ dataset/              # Raw .npy per-sample files
â”‚   â”œâ”€â”€ baby/
â”‚   â”œâ”€â”€ dog/
â”‚   â”œâ”€â”€ lebron/
â”‚   â”œâ”€â”€ mj/
â”‚   â”œâ”€â”€ rabbit/
â”‚   â””â”€â”€ shaq/
â”‚
â”œâ”€â”€ memes/ (optional)     # Or keep memes in project root
â”‚   â”œâ”€â”€ niche_baby.jpg
â”‚   â”œâ”€â”€ lebron_james.gif
â”‚   â”œâ”€â”€ mj.gif
â”‚   â”œâ”€â”€ rabbit.gif
â”‚   â”œâ”€â”€ shaq.gif
â”‚   â””â”€â”€ dog.gif
```

---
## ğŸ§ª Supported Gestures
| Gesture | Meaning | Meme Triggered |
|--------|----------|----------------|
| Hand on mouth | "Baby" expression | niche_baby.jpg |
| Hand on head | "Lebron frustrated" | lebron_james.gif |
| Tâ€‘pose with hands | Timeout gesture | shaq.gif |
| Pointing / holding | Rabbit meme | rabbit.gif |
| Crossed arms | MJ "Stop it" meme | mj.gif |
| No gesture (default) | Idle | dog.gif |

---
## ğŸ›  Installation
### 1. Install dependencies
```
pip install mediapipe opencv-python numpy scikit-learn joblib imageio pillow
```

---
## ğŸ¥ Step 1: Capture Gesture Samples
Run:
```
python data_capture.py
```

Press these keys while performing each gesture:
```
0 â†’ dog (default)
1 â†’ baby (hand on mouth)
2 â†’ lebron (hand on head)
3 â†’ shaq (T pose)
4 â†’ rabbit (pointing/holding)
5 â†’ mj (crossed arms)
```
Each press saves one sample.

â–¶ï¸ Recommended: **40+ samples per gesture** for good accuracy.

After collecting samples, press:
```
c â†’ combine into dataset.npz
```

---
## ğŸ¤– Step 2: Train the Model
Run:
```
python train_model.py
```
This will:
- load dataset.npz
- train a RandomForest classifier
- evaluate accuracy
- save `gesture_model.pkl`

---
## ğŸš€ Step 3: Run the Meme Reactor
```
python main.py
```
You will see two windows:
- **leepookie cam** â†’ webcam view
- **leepookie reaction** â†’ meme GIF based on prediction

Press `q` to quit.

---
## âš™ï¸ Optional: Rebuild Dataset Manually
If you added `.npy` files manually, run:
```
python build_dataset.py
```
This regenerates `dataset.npz` without recapturing.

---
## ğŸ”§ Troubleshooting
### Model is confused / misdetecting
- Ensure 30â€“50 samples **per gesture**
- Vary lighting, distance, and angle while capturing
- Retrain using `train_model.py`

### GIFs not animating
`imageio` is required.
```
pip install imageio
```

### Webcam not opening
If using VS Code, run from a **local terminal**, not inside a remote environment.

---
## ğŸ“˜ Tips for Better Accuracy
- Keep your face centered during capture
- Avoid harsh backlight
- Move slightly between each saved sample
- Capture at different distances
- Add more gestures easily by updating labels and retraining

---
## ğŸ§© Customize Your Own Gestures
Add a new folder under `dataset/`, capture `.npy` samples, rebuild dataset, retrain, and map it to any meme.

---
## ğŸ§‘â€ğŸ’» Credits
Created by **Nithin** â€” gesture-based meme reactor built with ML and MediaPipe.

Friends are free to modify, break, remix, and create meme chaos.

---
## â­ If you share this on GitHub
Consider adding project tags:
```
mediapipe, opencv, machine-learning, gestures, cv2, meme-generator, python-project
```

---
## ğŸ‰ Enjoy creating chaos with gestures!

